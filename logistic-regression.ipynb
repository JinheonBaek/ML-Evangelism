{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (MNIST dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import math\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((X_train, y_train), (X_test, y_test)) = mnist.load_data()\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train : Train dataset(Image feature data) / X_test : Test dataset(Image feature data)\n",
    "X_train = X_train.reshape(60000, 28*28)\n",
    "X_test = X_test.reshape(10000, 28*28)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train: Train dataset(label data) / y_test : Test dataset(label data)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Image of X_train[0]\n",
    "plt.matshow(X_train[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show result label of X_train[0] (=5)\n",
    "y_train[0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Calculating Cost (calculate value range from 0 to 1)\n",
    "def sigmoid(n):\n",
    "    return 1 / (1 + np.exp(-n))\n",
    "\n",
    "print(sigmoid(-9))\n",
    "print(sigmoid(0))\n",
    "print(sigmoid(+9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(-100, 100)\n",
    "y = [sigmoid(i/10) for i in x]\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1\n",
    "num_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter\n",
    "w = np.random.uniform(low=-1.0, high=1.0, size=(28*28, 10))\n",
    "b = np.random.uniform(low=-1.0, high=1.0, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    # Predict y (=number 0~9)\n",
    "    y_predict = X_train.dot(w) + b\n",
    "    y_predict = sigmoid(y_predict)\n",
    "    \n",
    "    # Calculating Error\n",
    "    error = (y_predict.argmax(axis=1) != y_train.argmax(axis=1)).mean()\n",
    "    \n",
    "    # Print Error\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"{0:4} error = {1:.5f}\".format(epoch, error))\n",
    "    \n",
    "    # Gradient Descent for Multiple Variables\n",
    "    w = w - learning_rate * X_train.T.dot(y_predict - y_train)\n",
    "    b = b - learning_rate * (y_predict - y_train).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using calculated parameter\n",
    "y_predict = X_train.dot(w) + b\n",
    "y_predict = sigmoid(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Result Dataframe\n",
    "actual = y_train.argmax(axis=1)\n",
    "predict = y_predict.argmax(axis=1)\n",
    "\n",
    "pd.DataFrame({'actual': actual, 'predict': predict}).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using calculated parameter\n",
    "y_predict = X_test.dot(w) + b\n",
    "y_predict = sigmoid(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Result Dataframe\n",
    "actual = y_test.argmax(axis=1)\n",
    "predict = y_predict.argmax(axis=1)\n",
    "\n",
    "result = pd.DataFrame({'actual': actual, 'predict': predict})\n",
    "result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Error\n",
    "plt.matshow(X_test[8].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating accuracy\n",
    "accuracy = []\n",
    "\n",
    "for i in range(10):\n",
    "    chunk = result[result[\"actual\"] == i]\n",
    "    accuracy.append((chunk[\"actual\"] == chunk[\"predict\"]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'accuracy' : accuracy})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make request to azure function for score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_url = \"https://jinheon-azureml-score.azurewebsites.net/api/Logistic-Regression-Score?code=gG5CmUzXsaBY2bCStVdAvltwagL4e7q15zTipWJCDW0xsgMlVUamUg==\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json = {\n",
    "    \"name\": \"Jinheon\",\n",
    "    \"score\": result['accuracy'].mean()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "req = requests.request('POST', _url, json = json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(req.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
